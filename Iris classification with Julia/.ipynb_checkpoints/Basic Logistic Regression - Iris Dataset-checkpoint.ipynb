{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression in Julia - Iris Dataset\n",
    "\n",
    "This notebook will be a basic implementation of logistic regression using the Julia programming language.  As described on their [website](https://julialang.org/)\n",
    "\n",
    "> Julia is a high-level, high-performance dynamic programming language for numerical computing. It provides a sophisticated compiler, distributed parallel execution, numerical accuracy, and an extensive mathematical function library.\n",
    "\n",
    "### Acquiring the Dataset\n",
    "\n",
    "The obvious first step is to download the Dataset.  Julia has a HTTP package as part of its library, as well as a *readcsv* and *writecsv* functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using HTTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×5 Array{Any,2}:\n",
       " 5.1  3.5  1.4  0.2  \"Iris-setosa\"\n",
       " 4.9  3.0  1.4  0.2  \"Iris-setosa\"\n",
       " 4.7  3.2  1.3  0.2  \"Iris-setosa\"\n",
       " 4.6  3.1  1.5  0.2  \"Iris-setosa\"\n",
       " 5.0  3.6  1.4  0.2  \"Iris-setosa\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the iris dataset\n",
    "res = HTTP.get(\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\");\n",
    "data_csv = readcsv(res.body); \n",
    "\n",
    "# Julia has 1 based indexing, not 0\n",
    "data_csv[1:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "\n",
    "The first 5 rows can be seen above.  Since the labels are currently strings, they will need to be converted to numbers.  I did this by finding all the unique labels and mapping them to an index.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{SubString{String},Int64} with 3 entries:\n",
       "  \"Iris-virginica\"  => 3\n",
       "  \"Iris-setosa\"     => 1\n",
       "  \"Iris-versicolor\" => 2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the data into features/labels\n",
    "X = Array{Float64}(data_csv[:,1:4]);\n",
    "Y_dirty = data_csv[:, 5];\n",
    "\n",
    "# m: number of examples\n",
    "# n: number of features\n",
    "m, n = size(X);\n",
    "\n",
    "# unique labels in Y\n",
    "unique_labels = unique(Y_dirty);\n",
    "# map labels to an integer value\n",
    "unique_labels_dict = Dict([label => i for (i, label) in enumerate(unique_labels)]);\n",
    "unique_labels_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once I had an index for each of the unique labels, I mapped each label in y to the integer index.  Then I converted the integer labels to a one-hot array with dimensions (m, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6×3 Array{Int32,2}:\n",
       " 1  0  0\n",
       " 1  0  0\n",
       " 1  0  0\n",
       " 0  1  0\n",
       " 0  1  0\n",
       " 0  1  0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numerical labels - this will be used later for comparisons\n",
    "labels = [unique_labels_dict[label] for (i, label) in enumerate(Y_dirty)];\n",
    "\n",
    "#convert Y from m x 1 string array to m x 3 one-hot array\n",
    "Y = zeros(Int32, (m,length(unique_labels_dict)));\n",
    "[Y[i,j] = 1 for (i, j) in enumerate(labels)];\n",
    "Y[48:53,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, add a column of ones to X (for the bias values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150×5 Array{Float64,2}:\n",
       " 1.0  5.1  3.5  1.4  0.2\n",
       " 1.0  4.9  3.0  1.4  0.2\n",
       " 1.0  4.7  3.2  1.3  0.2\n",
       " 1.0  4.6  3.1  1.5  0.2\n",
       " 1.0  5.0  3.6  1.4  0.2\n",
       " 1.0  5.4  3.9  1.7  0.4\n",
       " 1.0  4.6  3.4  1.4  0.3\n",
       " 1.0  5.0  3.4  1.5  0.2\n",
       " 1.0  4.4  2.9  1.4  0.2\n",
       " 1.0  4.9  3.1  1.5  0.1\n",
       " 1.0  5.4  3.7  1.5  0.2\n",
       " 1.0  4.8  3.4  1.6  0.2\n",
       " 1.0  4.8  3.0  1.4  0.1\n",
       " ⋮                      \n",
       " 1.0  6.0  3.0  4.8  1.8\n",
       " 1.0  6.9  3.1  5.4  2.1\n",
       " 1.0  6.7  3.1  5.6  2.4\n",
       " 1.0  6.9  3.1  5.1  2.3\n",
       " 1.0  5.8  2.7  5.1  1.9\n",
       " 1.0  6.8  3.2  5.9  2.3\n",
       " 1.0  6.7  3.3  5.7  2.5\n",
       " 1.0  6.7  3.0  5.2  2.3\n",
       " 1.0  6.3  2.5  5.0  1.9\n",
       " 1.0  6.5  3.0  5.2  2.0\n",
       " 1.0  6.2  3.4  5.4  2.3\n",
       " 1.0  5.9  3.0  5.1  1.8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [ones(m,1) X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model\n",
    "\n",
    "Since I'm just testing out Julia for the first time and writing everything from scratch, I decided to create a simple logistic regression model with sigmoid activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function initialize_weights(W_shape)\n",
    "    weights = rand(W_shape);\n",
    "    \n",
    "    weights;\n",
    "end\n",
    "\n",
    "# numerical operation syntax is the same as matlab/octave \n",
    "# with . to represent elementwise operations\n",
    "function sigmoid(Z)\n",
    "    1.0 ./ (1.0 .+ exp.(-Z));\n",
    "end\n",
    "\n",
    "function linear_forward(X, W)\n",
    "    X * W;\n",
    "end\n",
    "\n",
    "function activation(Z)\n",
    "    sigmoid(Z);\n",
    "end\n",
    "\n",
    "function predict(X, W)\n",
    "    activation(linear_forward(X, W));\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost function will compute both the cost and gradient where cost J is\n",
    "$$\n",
    "J = \\frac{1}{m} \\left (-Y^Tlog(H) - (1-Y)^Tlog(1-H) \\right )\n",
    "$$\n",
    "and the gradient is\n",
    "$$\n",
    "grad = \\frac{1}{m}X^T (H - Y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cost (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function cost(X, Y, W)\n",
    "    m = size(Y, 1);\n",
    "    H = predict(X, W);\n",
    "    \n",
    "    cost_1 = Y' * log.(H);\n",
    "    cost_0 = (1 .- Y)' * log.(1 .- H);  \n",
    "    cost = -sum(cost_1 + cost_0) / m;\n",
    "    \n",
    "    error = H .- Y\n",
    "    grad = X' * (error) / m;\n",
    "    cost, grad;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function train(X, Y, learning_rate = 0.01, iterations = 10000)\n",
    "    n = size(X, 2)\n",
    "    m = size(X, 1)\n",
    "    num_classes = size(Y, 2)\n",
    "    \n",
    "    W = initialize_weights((n, num_classes));\n",
    "    costs = Array{Float64}(0);\n",
    "    for i = 1:iterations\n",
    "        J, dW = cost(X, Y, W);  \n",
    "        W = W .- learning_rate .* dW;\n",
    "        \n",
    "        if i % 50 == 0\n",
    "            append!(costs,J);\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    W, costs\n",
    "end\n",
    "\n",
    "W, costs = train(X, Y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.67%"
     ]
    }
   ],
   "source": [
    "# make predictions for X using the calculated weights\n",
    "predictions = predict(X, W);\n",
    "# convert the mx3 prediction matrix to a mx1 label\n",
    "prediction_labels = [indmax(predictions[x,:]) for x = 1:size(predictions,1)]\n",
    "\n",
    "correct_predictions = sum(prediction_labels .== labels)\n",
    "accuracy = 100 * correct_predictions / m\n",
    "@printf(\"Accuracy: %.2f%%\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision, Recall, and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-setosa:\n",
      "\tPrecision: 1.000\n",
      "\tRecall: 0.909\n",
      "\tF1 Score: 0.952\n",
      "Iris-versicolor:\n",
      "\tPrecision: 0.920\n",
      "\tRecall: 0.979\n",
      "\tF1 Score: 0.948\n",
      "Iris-virginica:\n",
      "\tPrecision: 0.980\n",
      "\tRecall: 0.925\n",
      "\tF1 Score: 0.951\n"
     ]
    }
   ],
   "source": [
    "tp = [sum(prediction_labels .== labels .== i) for i = 1:3]\n",
    "fp = [sum(prediction_labels .!= labels .== i) for i = 1:3]\n",
    "fn = [sum(prediction_labels .!= labels .!= i) for i = 1:3]\n",
    "\n",
    "precision = tp ./ (tp .+ fp)\n",
    "recall = tp ./ (tp .+ fn)\n",
    "f1 = 2 * (precision .* recall) ./ (precision .+ recall)\n",
    "\n",
    "for i = 1:3\n",
    "    @printf(\"%s:\\n\", unique_labels[i])\n",
    "    @printf(\"\\tPrecision: %.3f\\n\", precision[i])\n",
    "    @printf(\"\\tRecall: %.3f\\n\", recall[i])\n",
    "    @printf(\"\\tF1 Score: %.3f\\n\", f1[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.1",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
