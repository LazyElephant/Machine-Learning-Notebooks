{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim, cuda\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "base_file_path = './datasets/mnist-linear'\n",
    "is_cuda_available = cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (1.0,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = MNIST(root=base_file_path, train=True, download=True, transform=transform)\n",
    "test_set = MNIST(root=base_file_path, train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train batch length: 938\n",
      "test batch length: 157\n"
     ]
    }
   ],
   "source": [
    "print(f'train batch length: {len(train_loader)}')\n",
    "print(f'test batch length: {len(test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        output = self.main(input.view(-1, 28*28))\n",
    "        return output\n",
    "    \n",
    "net = Model()\n",
    "if is_cuda_available:\n",
    "    net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch index: 0, loss: 0.230135\n",
      "epoch: 0, batch index: 100, loss: 1.822987\n",
      "epoch: 0, batch index: 200, loss: 1.684910\n",
      "epoch: 0, batch index: 300, loss: 1.638735\n",
      "epoch: 0, batch index: 400, loss: 1.619424\n",
      "epoch: 0, batch index: 500, loss: 1.595652\n",
      "epoch: 0, batch index: 600, loss: 1.592176\n",
      "epoch: 0, batch index: 700, loss: 1.578991\n",
      "epoch: 0, batch index: 800, loss: 1.581174\n",
      "epoch: 0, batch index: 900, loss: 1.562377\n",
      "epoch: 1, batch index: 0, loss: 0.159342\n",
      "epoch: 1, batch index: 100, loss: 1.557920\n",
      "epoch: 1, batch index: 200, loss: 1.557756\n",
      "epoch: 1, batch index: 300, loss: 1.544618\n",
      "epoch: 1, batch index: 400, loss: 1.548617\n",
      "epoch: 1, batch index: 500, loss: 1.534168\n",
      "epoch: 1, batch index: 600, loss: 1.539785\n",
      "epoch: 1, batch index: 700, loss: 1.542710\n",
      "epoch: 1, batch index: 800, loss: 1.542438\n",
      "epoch: 1, batch index: 900, loss: 1.531007\n",
      "epoch: 2, batch index: 0, loss: 0.153298\n",
      "epoch: 2, batch index: 100, loss: 1.527688\n",
      "epoch: 2, batch index: 200, loss: 1.530555\n",
      "epoch: 2, batch index: 300, loss: 1.531263\n",
      "epoch: 2, batch index: 400, loss: 1.521184\n",
      "epoch: 2, batch index: 500, loss: 1.527817\n",
      "epoch: 2, batch index: 600, loss: 1.523286\n",
      "epoch: 2, batch index: 700, loss: 1.527638\n",
      "epoch: 2, batch index: 800, loss: 1.511405\n",
      "epoch: 2, batch index: 900, loss: 1.521472\n",
      "epoch: 3, batch index: 0, loss: 0.148329\n",
      "epoch: 3, batch index: 100, loss: 1.523227\n",
      "epoch: 3, batch index: 200, loss: 1.510610\n",
      "epoch: 3, batch index: 300, loss: 1.516702\n",
      "epoch: 3, batch index: 400, loss: 1.519816\n",
      "epoch: 3, batch index: 500, loss: 1.515595\n",
      "epoch: 3, batch index: 600, loss: 1.511146\n",
      "epoch: 3, batch index: 700, loss: 1.514082\n",
      "epoch: 3, batch index: 800, loss: 1.507477\n",
      "epoch: 3, batch index: 900, loss: 1.506620\n",
      "epoch: 4, batch index: 0, loss: 0.149880\n",
      "epoch: 4, batch index: 100, loss: 1.505346\n",
      "epoch: 4, batch index: 200, loss: 1.514946\n",
      "epoch: 4, batch index: 300, loss: 1.508190\n",
      "epoch: 4, batch index: 400, loss: 1.500354\n",
      "epoch: 4, batch index: 500, loss: 1.501810\n",
      "epoch: 4, batch index: 600, loss: 1.495965\n",
      "epoch: 4, batch index: 700, loss: 1.500093\n",
      "epoch: 4, batch index: 800, loss: 1.510380\n",
      "epoch: 4, batch index: 900, loss: 1.504987\n",
      "epoch: 5, batch index: 0, loss: 0.149238\n",
      "epoch: 5, batch index: 100, loss: 1.509516\n",
      "epoch: 5, batch index: 200, loss: 1.501914\n",
      "epoch: 5, batch index: 300, loss: 1.502628\n",
      "epoch: 5, batch index: 400, loss: 1.499084\n",
      "epoch: 5, batch index: 500, loss: 1.496059\n",
      "epoch: 5, batch index: 600, loss: 1.501628\n",
      "epoch: 5, batch index: 700, loss: 1.495115\n",
      "epoch: 5, batch index: 800, loss: 1.496703\n",
      "epoch: 5, batch index: 900, loss: 1.495471\n",
      "epoch: 6, batch index: 0, loss: 0.147372\n",
      "epoch: 6, batch index: 100, loss: 1.490517\n",
      "epoch: 6, batch index: 200, loss: 1.495838\n",
      "epoch: 6, batch index: 300, loss: 1.495889\n",
      "epoch: 6, batch index: 400, loss: 1.489124\n",
      "epoch: 6, batch index: 500, loss: 1.494476\n",
      "epoch: 6, batch index: 600, loss: 1.491758\n",
      "epoch: 6, batch index: 700, loss: 1.494256\n",
      "epoch: 6, batch index: 800, loss: 1.494489\n",
      "epoch: 6, batch index: 900, loss: 1.498400\n",
      "epoch: 7, batch index: 0, loss: 0.152140\n",
      "epoch: 7, batch index: 100, loss: 1.494866\n",
      "epoch: 7, batch index: 200, loss: 1.489381\n",
      "epoch: 7, batch index: 300, loss: 1.488768\n",
      "epoch: 7, batch index: 400, loss: 1.484651\n",
      "epoch: 7, batch index: 500, loss: 1.486869\n",
      "epoch: 7, batch index: 600, loss: 1.481806\n",
      "epoch: 7, batch index: 700, loss: 1.490086\n",
      "epoch: 7, batch index: 800, loss: 1.489938\n",
      "epoch: 7, batch index: 900, loss: 1.485483\n",
      "epoch: 8, batch index: 0, loss: 0.149509\n",
      "epoch: 8, batch index: 100, loss: 1.485674\n",
      "epoch: 8, batch index: 200, loss: 1.490465\n",
      "epoch: 8, batch index: 300, loss: 1.486824\n",
      "epoch: 8, batch index: 400, loss: 1.482443\n",
      "epoch: 8, batch index: 500, loss: 1.488190\n",
      "epoch: 8, batch index: 600, loss: 1.486702\n",
      "epoch: 8, batch index: 700, loss: 1.489639\n",
      "epoch: 8, batch index: 800, loss: 1.488453\n",
      "epoch: 8, batch index: 900, loss: 1.487261\n",
      "epoch: 9, batch index: 0, loss: 0.148708\n",
      "epoch: 9, batch index: 100, loss: 1.484563\n",
      "epoch: 9, batch index: 200, loss: 1.483282\n",
      "epoch: 9, batch index: 300, loss: 1.484012\n",
      "epoch: 9, batch index: 400, loss: 1.484817\n",
      "epoch: 9, batch index: 500, loss: 1.486025\n",
      "epoch: 9, batch index: 600, loss: 1.482205\n",
      "epoch: 9, batch index: 700, loss: 1.488022\n",
      "epoch: 9, batch index: 800, loss: 1.488621\n",
      "epoch: 9, batch index: 900, loss: 1.479860\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    average_loss = 0\n",
    "    for i, (x, target) in enumerate(train_loader):\n",
    "        if is_cuda_available:\n",
    "            x, target = x.cuda(), target.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        x, target = Variable(x), Variable(target)\n",
    "        out = net(x)\n",
    "        loss = criterion(out, target)\n",
    "        average_loss = average_loss * 0.9 + loss.data[0] * 0.1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print('epoch: {}, batch index: {}, loss: {:.6f}'.format(epoch, i, average_loss))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.487247, acc: 0.972\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_count = 0\n",
    "correct_count = 0\n",
    "average_loss = 0\n",
    "for i, (x, target) in enumerate(test_loader):\n",
    "    if is_cuda_available:\n",
    "        x, target = x.cuda(), target.cuda()\n",
    "        \n",
    "    x, target = Variable(x), Variable(target)\n",
    "    out = net(x)\n",
    "    loss = criterion(out, target)\n",
    "    _, predicted_label = torch.max(out.data, 1)\n",
    "    total_count += x.data.size()[0]\n",
    "    correct_count += (predicted_label == target.data).sum()\n",
    "    average_loss = average_loss * 0.9 + loss.data[0] * 0.1\n",
    "    \n",
    "\n",
    "print('test loss: {:.6f}, acc: {:.3f}'.format(average_loss, correct_count * 1.0 / total_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
